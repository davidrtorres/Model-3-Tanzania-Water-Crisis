{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, Normalizer, FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno \n",
    "\n",
    "dashes = dashes='---'*20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "According to the World Health Organization, one out of six people in Tanzania lack access to safe drinking water. Women and children must walk long distances to find water.  In rural Tanzania people walk for 2 to 3 km daily in search of water from public taps where available or natural streams.  They must carrying heavy containers for the water on their heads of about 20 to 25 litres per trip.  When they find water there is a problem of long lines at the point of water tap or boreholes where people spend hours to wait for their turn.  The water shortage has been caused by population growth, high level consumption and climate change which has reduced the resources of water.  Water shortages lead to poor sanitation, lack of safe drinking water, and overcrowding at water sources. projectzawadi.org.\n",
    "\n",
    "The Tanzanian Ministry of Water is seeking to solve the ongoing water crisis in Tanzania by increasing the number of functioning water wells.  It is crucial to the health and safety of communities that its residents have access to drinking water.  Tanzania has a lot of water wells that are non-functioning or in need of repair.  Predictive modeling can be used to aid in solving this problem. <br> \n",
    "<BR>\n",
    "My objective is to build classification models that will predict the operating status of water wells based on features in the dataset.  The data was gathered by Taarifa from the Tanzanian Ministry of Water and consist of over 59,400 data points of water well pumps in Tanzania and 40 features. The data consists of features regarding the pumps, such as installer, install date, location and pump type, etc.  The data also includes a target variable indicating the status of the functionality of the pumps.  The functioning status of the wells are identifed as  functioning, non-functioning or functioning but in need of repairs.  \n",
    "<BR>\n",
    "In addition, I will provide an analysis and visualizations of the data to provide insights and information of how various features impact the operating status of water wells, e.g., does location of the wells impact the liklihood the wells will be functioning or non-functioning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "df_1 = pd.read_csv('data/water_table.csv')\n",
    "labels = pd.read_csv('data/water_table_labels.csv')\n",
    "df_1['target'] = labels['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['target'] = df_1['target'].map({'functional':0,'non functional':1,'functional needs repair':2})\n",
    "df_1.drop('id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['date_recorded'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The following are issues with the data that need to be addressed.  These issues will be addressed by issue and feature.<br>\n",
    "There are several features that have Null values.  We can impute the Null values with medium values of the feature.<br>\n",
    "There are several columns have a 0 as the category and constitutes a significant part of the feature. \n",
    "There features are duplicates of other features in the dataset.  We will not include duplicate features in the dataset.<br>\n",
    "There are several features that have object values and numerous unique features.  The features will need to be One-Hot encoded for modeling purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "The features funder, installer, subvillage, public meeting, scheme_management, scheme_name, permit have object values and NaN values.  We will impute the NaN values with the median values of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_value_status(data, feature):\n",
    "    #function provides count and percentage of each value\n",
    "    vc= df_2[feature]\n",
    "    count = vc.value_counts(dropna=False)\n",
    "    percent = vc.value_counts(normalize=True)\n",
    "    percent100 = vc.value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n",
    "    count_df = pd.DataFrame({'count': count, 'per': percent,'%': percent100})\n",
    "    return count_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amount_tsh\n",
    "This feature is defined as the total static head or the amount of water avaliable to waterpoint. According to below, 70% of the values of this feature are 0.  This is too big of a percentage to do any imputing of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'amount_tsh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funder\n",
    "This feature has 3635 NaN values.  There is a value of 'O' so we can group all NaN value with those of 'O'.  In addition, this feature values are non-numeric and there are 1,897 unique values.  The unique values will be need to be One-Hot Encoded for modeling purposes.  We  will group all unique values of 100 or less and put them in a categery entitled 'Unknown'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'funder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'] = df_2['funder'].replace(np.nan, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of unique categories in the feature funder are: {len(df_2['funder'].unique())}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.apply(lambda x: x.mask(x.map(x.value_counts())< 100, 'other') if x.name=='funder' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "df_2['funder'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gps_height \n",
    "This feature has a value of 0 which is 34.4% of the feature.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'gps_height') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_2['gps_height'][df_2['gps_height'] != 0].mean()\n",
    "df_2['gps_height'].replace(0, mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'gps_height') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### installer\n",
    "This feature is defined as the organization that installed the well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'installer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longitude\n",
    "This feature is defined as the GPS coordinate.  #% of this feature has a value of 0.  I used the mean value of the feature to impute the 0 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'longitude') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_mean = df_2[df_2['longitude']>0]['longitude'].mean()\n",
    "df_2.loc[df_2['longitude']==0.00, 'longitude'] = float(longitude_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['longitude'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latitude\n",
    "This feature is defined as the GPS coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2['latitude'].value_counts(normalize=True)\n",
    "count_value_status(df_2, 'latitude') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_mean = df_2[df_2['latitude']>0]['latitude'].mean()\n",
    "df_2.loc[df_2['latitude']==0, 'latitude'] = float(latitude_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wpt_name and num_private\n",
    "wpt_name is defined as the name of the name of the well.  This feature is an object and has 37,400 unique values.  This would be toom any to One_Hot Encode for modeling purposes and will not be included in the dataset.<br>\n",
    "\n",
    "For num_private, 98.7% of the feature has a value of 0.  This is too many values to impute and will not be included in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['wpt_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'num_private') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basin\n",
    "This is feature is defined as the geographic water basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'basin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "subvillage : Geographic location\n",
    "region : Geographic location\n",
    "\n",
    "region_code : Geographic location (coded)\n",
    "district_code : Geographic location (coded)\n",
    "\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'region_code') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'district_code') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGA and Ward\n",
    "These features are both defined as the geographic location of the wells.  LGA  has 125 unique value and ward has 2092 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lga                    59400 non-null  object \n",
    " 15  ward  \n",
    "\"\"\"\n",
    "count_value_status(df_2, 'lga') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_value_status(df_2, 'ward')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.apply(lambda x: x.mask(x.map(x.value_counts())< 100, 'Other') if x.name=='lga' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'lga') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population\n",
    "population is defined as the population around the well.  36% of water wells have 0 population around them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'population') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_mean = df_2[df_2['population']>0]['population'].mean()\n",
    "df_2.loc[df_2['population']==0, 'population'] = int(population_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'population') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'public_meeting') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df_2[\"public_meeting\"].mode()[0]\n",
    "df_2[\"public_meeting\"].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['public_meeting'] = list(map(int, df_2['public_meeting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'public_meeting') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scheme_management\n",
    "scheme_management : Who operates the waterpoint\n",
    "scheme_name : Who operates the waterpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'scheme_management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['scheme_management'] = np.where(df_2['scheme_management'].isnull(),\"Unknown\",df_2['scheme_management'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'scheme_management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "permit is defined as if the well is permitted or not.\n",
    "There are 38852 NaN value.  We can impute NaN to the category with most values.  We need to als also convet the boleean values to \n",
    "numeric.\n",
    "\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=df_2[\"permit\"].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df_2[\"permit\"].mode()[0]\n",
    "df_2[\"permit\"].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['permit'] = list(map(int, df_2['permit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construction_year\n",
    "The feature construction_year is defined as the year the waterpoint was constructed.  Unfortnately, 34% of the feature is categorized as 0.  I will replacing the 0 values from the construction year column with the average year year values for the feature. With the cleaned construction year feature I will use feature engineering to create a pump age and an average popultion served per year feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'construction_year') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_test['construction_year'] = X_test['construction_year'].replace({0:1993})\n",
    "\n",
    "mean_yr = df_2[df_2['construction_year']>0]['construction_year'].mean()\n",
    "df_2.loc[df_2['construction_year']==0, 'construction_year'] = int(mean_yr)\n",
    "\"\"\"\n",
    "mean = df_2['construction_year'][df_2['construction_year'] != 0].mean()\n",
    "df_2.construction_year.replace(0, mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'construction_year') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extraction_type_class\n",
    "The features extraction_type, extraction_type_group, extraction_type_class are defined as the kind of extraction the waterpoint uses.  I only included extraction_type_class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'extraction_type_class') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### management\n",
    "Both management and management_group are defined as how the waterpoints are managed.  I only included management in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.groupby(['management', 'management_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### payment\n",
    "The features payment and payment_type are defined as what the water costs.  I only included payment in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "payment\n",
    "payment-what the water costs\n",
    "payment_type\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'payment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quality_group\n",
    "Both water_quality and quality_group are defined as the quality of the water.  I only included quality_group in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "water_quality - the quality of water\n",
    "quality_group - the quality of water\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'quality_group') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quantity_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'quantity_group') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source\n",
    "The features source, source_type and source_class are defined as the source of the water.  The features are duplicates with some variations.  I included only source in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'source') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### waterpoint_type\n",
    "Both features waterpoint_type and waterpoint_type_group have the same defintion and are defined as the kind of waterpoint.  I only included waterpoint_type in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'waterpoint_type') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### age\n",
    "With feature engineering I created a feature to identify the age of the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features['construction_year'] = features['construction_year'].replace({0:1993})\n",
    "df_2['age'] = df_2['date_recorded'].astype(str).str[:4].astype(int) - df_2['construction_year']\n",
    "df_2['pop_per_year'] = df_2['population'].replace({0:1}) / df_2['age'].replace({0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'age') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['age'] = X_test['date_recorded'].astype(str).str[:4].astype(int) - X_test['construction_year']\n",
    "# X_test['pop/year'] = X_test['population'].replace({0:1}) / X_test['age'].replace({0:1})\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_w_hue(df, col= None, hue_col=None, rot=None, figsize=None):\n",
    "    \"\"\"\n",
    "    plots a seaborn countplot for column and hue w/customization\n",
    "    Args\n",
    "    df (dataframe)\n",
    "    col (int or str)\n",
    "    hue_col (int or str)\n",
    "    rot(rotate x label)\n",
    "    figsize (dict)\n",
    "    \"\"\"\n",
    "#     print(df[col].value_counts(dropna=False))\n",
    "#     print('\\n')\n",
    "#     print(round(df[col].value_counts(normalize=True),3))\n",
    "#     dashes = dashes='---'*15\n",
    "#     print(dashes)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    #sns.countplot(data=data, x=col, ax=ax)\n",
    "    sns.countplot(data=df, x=col, hue=hue_col, ax=ax)\n",
    "    label_font = {'weight':'bold','size':15}\n",
    "    ax.set_ylabel('Counts',fontdict=label_font)\n",
    "    ax.set_xlabel(col,fontdict=label_font)\n",
    "    #ax.set_title(f'Distribution of {col.title()}',fontdict=label_font)\n",
    "    ax.set_title(f'How {col.title()} relates to {hue_col.title()}',fontdict=label_font)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontdict={'rotation':rot,'ha':'right'}); \n",
    "    #ax.set_xticklabels(ticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distribution(data, col= None, ticklabels=None, figsize=None):\n",
    "    \"\"\"\n",
    "    plots a seaborn countplot for feature w/customization\n",
    "    \n",
    "    Args\n",
    "        df (df)\n",
    "        col (int or str)\n",
    "        figsize (dict)\n",
    "    \"\"\"\n",
    "    print(data[col].value_counts(dropna=False))\n",
    "    print('\\n')\n",
    "    print(round(data[col].value_counts(normalize=True),3))\n",
    "    dashes = dashes='---'*15\n",
    "    print(dashes)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    sns.countplot(data=data, x=col, ax=ax)\n",
    "    label_font = {'weight':'bold','size':15}\n",
    "    ax.set_ylabel('Counts',fontdict=label_font)\n",
    "    ax.set_xlabel(col,fontdict=label_font)\n",
    "    ax.set_title(f'Distribution of {col.title()}',fontdict=label_font)\n",
    "    ax.set_xticklabels(ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target\n",
    "The target is imbalanced because category 0 which is 54% of the feature, category 1 is 38% and category 2 is 0.07% of the feature.  The imblance could impact the model's performance so it will be addressed further below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_distribution(df_1, col='target',ticklabels=['functional / 0','non-functional / 1','functional needs repair / 2'],figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### district_code\n",
    "The below plot shows that districts 1,2,3 4 have the highest number of performing wells.  However, there is also a large number of non-functioning wells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='district_code', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### funder\n",
    "We were looking to see if the top funders give us some indcation of the functionlaity of the wells.  Other is the largest category which isn't helpful because it's not specific. Government Of Tanzania is the next largest group and they have funded 9084 wells.  A little over 4,000 wells are functioning but around 5,000 wells aren't functioning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'].value_counts(dropna=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funder_10 = df_3[(df_3['funder'] == 'other') | (df_3[\"funder\"] == 'Government Of Tanzania')\n",
    "                 |(df_3[\"funder\"] == '0')| (df_3[\"funder\"] == 'Danida')\n",
    "                 |(df_3[\"funder\"] == 'Hesawa') |(df_3[\"funder\"] == 'Rwssp') \n",
    "                 |(df_3[\"funder\"] == 'World Bank') |(df_3[\"funder\"] == 'Kkkt')\n",
    "                 | (df_3[\"funder\"] == 'World Vision')| (df_3[\"funder\"] == 'Unicef')\n",
    "                  | (df_3[\"funder\"] == 'Tasaf')]\n",
    "funder_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(funder_10, col='funder', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does location impact functionality of a well\n",
    "The below plot is really helpful because it shows where the wells are located and their functionality.  In the southeast section there is a cluster of non-functioning wells.  Further research is warranted.  Is there any correlation with district, population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='target', data=df_2)#, ax=ax\n",
    "plt.title('Water Well Location and Functionality')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does region_code impact functionality?\n",
    "It's interesting to see which districts have the highest number of wells and their status.  Region \n",
    "11 has highest number of wells and around 4,200 are functioning, around 1,000 are non-functioning and\n",
    "around 100 are in eed of repairs.  Region 17 has 3,000 functioning wells and 1,500 are non-functioning.  \n",
    "The plot gives us a quick summary of the number of wells in each district and their status.  It shoes\n",
    "that regions 8,9,40, 60, 80, 90 and 99 have very few wells and most are non-functioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='region_code', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the quality of the water impact functionality\n",
    "The plot show that there are 6 kinds of wate quality.  The majority of the wells fall under the category of \n",
    "of good and around 39,000 are functioning.  Around 18,000 are non-functioning.  If the well good water quality there is a higher chance that it is functioning but there is still a high probability it's not working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='quality_group', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does quantity of water impact well functionality?\n",
    "The below plot shows that wells with enough water constitute the largest number of wells and the \n",
    "highest functionality.  There are around 24,000 functioning wells with enough water and with wells with \n",
    "enough water around 9,000 are non-functioning.  Based on the below it looks like if the well has a enought water \n",
    "it contributing to the functionality of the well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='quantity_group', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = count_value_status(df_2, 'age').head(20)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='age', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of Data\n",
    "The pre-processing of the data will involve One-Hot Encoding the features with object data types because\n",
    "non-numeric values can't be inputted into the models.  In addition, this is a ternary classification problem because the target has three classifiction values: functional, non functional and functional needs repair. As displayed above we can see that value_counts are not balanced.  This could impact the accuracy of the model's performance.  I  ran the SMOTE method the training set to resample the set and get equal values for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_obj = ['funder','installer','basin','lga','scheme_management','extraction_type_class','management','payment','quality_group',\n",
    "            'quantity_group','source','waterpoint_type']\n",
    "cols_num = ['gps_height','latitude','longitude','district_code','region_code','permit','construction_year','population','age','pop_per_year']\n",
    "\n",
    "df_3 = df_2[cols_obj]\n",
    "df_4 = df_2[cols_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(df_3, cols_obj, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df_4, one_hot_df], axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result.copy()\n",
    "y = df_2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_resampled.shape)\n",
    "print(y_train_resampled.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dict = {\n",
    "    'KNN': { 'model' : KNeighborsClassifier(),\n",
    "                         'params' : { \n",
    "                                        \"n_neighbors\" : [3,5,7,9,11,15,19],#,5,7,9,11,13,15\n",
    "                                        \"weights\" : ['uniform', 'distance']}\n",
    "             },\n",
    "    'logisticR': { 'model' : LogisticRegression(),\n",
    "                         'params' : { \n",
    "                             'fit_intercept':[False], \n",
    "                             'C':[1e12], \n",
    "                             'solver':['liblinear']}\n",
    "             }\n",
    "#     'random_forest': {\n",
    "#         'model': RandomForestClassifier(),\n",
    "#         'params': {\n",
    "#              'bootstrap': [True],\n",
    "#             #'max_depth': [80, 90],\n",
    "#             'max_features': ['auto', 'sqrt'],\n",
    "#             #'min_samples_leaf': [3, 4, 5],\n",
    "#             'min_samples_split': [5, 10],\n",
    "#             'n_estimators': [100,200],#[100, 200, 300,500]\n",
    "#             # 'n_estimators': [100,150],\n",
    "#             # #'max_depth': [int(x) for x in np.linspace(10, 15, num = 11)],\n",
    "#             # 'max_features': ['auto', 'sqrt'],\n",
    "#             #  'min_samples_split': [5,10],\n",
    "#              'class_weight':['balanced'],\n",
    "#               'criterion' :['gini', 'entropy']}\n",
    "#              }\n",
    "\n",
    "\n",
    "              \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = []\n",
    "for model_name, mp in model_dict.items():\n",
    "     clf = GridSearchCV(mp['model'], mp['params'],cv=5,  return_train_score=False) #refit='f1_weighted',\n",
    "     clf.fit(X_train, y_train)\n",
    "     y_pred = clf.predict(X_test) \n",
    "    \n",
    "     accuracy = accuracy_score(y_test, y_pred)\n",
    "     scores.append({\n",
    "      'model':model_name,\n",
    "      'accuracy': accuracy,\n",
    "      'best params': clf.best_params_\n",
    "      })\n",
    "pd.set_option('display.max_colwidth', None)    \n",
    "gscv_models = pd.DataFrame(scores) #, columns=['model', 'accuracy', 'f1', 'roc','best score','best params']\n",
    "gscv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(X_train_resampled, X_test, y_train_resampled, y_pred,\n",
    "                              normalize='true',cmap='Blues',figsize=[10,5]):\n",
    "      \n",
    "    # Classification Report / Accuracy Score \n",
    "    print(dashes)\n",
    "    print(\"Classification Report\")\n",
    "    print(dashes)\n",
    "    classes = ['0/Functional','1/Non-functioning','2/Needs Repair']\n",
    "    print(metrics.classification_report(y_test,y_pred,target_names=classes))  \n",
    "    print(dashes)\n",
    "    print('\\n')\n",
    "   \n",
    "    plt.figure(figsize=(8,8))\n",
    "    rf_cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap='Blues')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = gscv_models.iloc[0]['best params']\n",
    "knn = KNeighborsClassifier(**knn_params)\n",
    "model_k = knn.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_k=model_k.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR_params = gscv_models.iloc[1]['best params']\n",
    "logisticR = LogisticRegression(**logisticR_params)\n",
    "model = logisticR.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_params = gscv_models.iloc[2]['best params']\n",
    "# rf = RandomForestClassifier(**rf_params)\n",
    "# model_rf = rf.fit(X_train_resampled, y_train_resampled)\n",
    "# y_pred_rf=model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_rf = eval_classification_model(X_train_resampled, X_test, \n",
    "#                  y_train_resampled, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_2.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "features = df_data.columns\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO don't use\n",
    "# param_grid = {'learning_rate': [0.075, 0.07],\n",
    "#                       'max_depth': [6, 7],\n",
    "#                       'min_samples_leaf': [7,8],\n",
    "#                       'max_features': [1.0],\n",
    "#                       'n_estimators':[100, 200]} \n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,\n",
    "#                             criterion= 'entropy',max_features= 'sqrt',\n",
    "#                              min_samples_split= 10,class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put is null values in unknown category\n",
    "# df_2['installer'] = np.where(df_2['installer'].isnull(),\"Unknown\",df_2['installer'])\n",
    "\n",
    "# df_2['installer'] = np.where(df_2['installer'].isnull(),\"Unknown\",df_2['installer'])\n",
    "\n",
    "# amount_tsh_mean = df_2[df_2['amount_tsh']>0]['amount_tsh'].mean()\n",
    "# df_2.loc[df_2['amount_tsh']==0, 'amount_tsh'] = int(amount_tsh_mean)\n",
    "\n",
    "# #Matt Kirby\n",
    "# features['construction_year'] = features['construction_year'].replace({0:1993})\n",
    "# features['age'] = features['date_recorded'].astype(str).str[:4].astype(int) - features['construction_year']\n",
    "# features['pop/year'] = features['population'].replace({0:1}) / features['age'].replace({0:1})\n",
    "\n",
    "# features['water_/_person'] = features['amount_tsh'].replace({0:1}) / features['population'].replace({0:1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
