{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno \n",
    "\n",
    "dashes = dashes='---'*20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "According to the World Health Organization, one out of six people in Tanzania lack access to safe drinking water. Women and children must walk long distances to find water.  In rural Tanzania people walk for 2 to 3 km daily in search of water from public taps where available or natural streams.  They must carrying heavy containers for the water on their heads of about 20 to 25 litres per trip.  When they find water there is a problem of long lines at the point of water tap or boreholes where people spend hours to wait for their turn.  The water shortage has been caused by population growth, high level consumption and climate change which has reduced the resources of water.  Water shortages lead to poor sanitation, lack of safe drinking water, and overcrowding at water sources. projectzawadi.org.\n",
    "\n",
    "The Tanzanian Ministry of Water is seeking to solve the ongoing water crisis in Tanzania by increasing the number of functioning water wells.  It is crucial to the health and safety of communities that its residents have access to drinking water.  Tanzania has a lot of water wells that are non-functioning or in need of repair.  Predictive modeling can be used to aid in solving this problem. <br> \n",
    "<BR>\n",
    "My objective is to build classification models that will predict the operating status of water wells based on features in the dataset.  The data was gathered by Taarifa from the Tanzanian Ministry of Water and consists of over 59,400 data points of water well pumps in Tanzania and 40 features. The data consists of features regarding the pumps, such as installer, install date, location and pump type, etc.  The data also includes a target variable indicating the status of the functionality of the pumps.  The functioning status of the wells are identifed as  functioning, non-functioning or functioning but in need of repairs.  \n",
    "<BR>\n",
    "In addition, I will provide an analysis and visualizations of the data to provide insights and information on  the relationship between the features and the operating status of water wells, e.g., does location of the wells impact the liklihood the wells will be functioning or non-functioning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "df_1 = pd.read_csv('data/water_table.csv')\n",
    "labels = pd.read_csv('data/water_table_labels.csv')\n",
    "df_1['target'] = labels['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['target'] = df_1['target'].map({'functional':0,'non functional':1,'functional needs repair':2})\n",
    "df_1.drop('id',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['date_recorded'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The following are issues with the data that need to be addressed.  These issues will be addressed by issue and feature.<br>\n",
    "There are several features that have Null values.  I will impute the NaN values with medium values of the feature.<br>\n",
    "There are several features that have a 0 as a category.  This category will need to be renamed or dropped depending on their percentage of the feature.<br> \n",
    "There are features that are duplicates or variations of other features in the dataset.  We will not include duplicate features in the dataset.<br>\n",
    "There are several features that have object values and numerous unique categories.  The features will need to be One-Hot encoded for modeling purposes.  The features with too many unique values the lower count categories will be grouped.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values\n",
    "The features funder, installer, subvillage, public meeting, scheme_management, scheme_name, permit have object values and NaN values.  We will impute the NaN values with the median values of their respective features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_value_status(data, feature):\n",
    "    #function provides count and percentage of each value\n",
    "    vc= df_2[feature]\n",
    "    count = vc.value_counts(dropna=False)\n",
    "    percent = vc.value_counts(normalize=True)\n",
    "    percent100 = vc.value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n",
    "    count_df = pd.DataFrame({'count': count, 'per': percent,'%': percent100})\n",
    "    return count_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### amount_tsh\n",
    "This feature is defined as the total static head or the amount of water avaliable to waterpoint. According to below, 70% of the values of this feature are 0.  This is too big of a percentage to do any imputing of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'amount_tsh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funder\n",
    "Funder is defined as who funded the well.  This feature has 3635 NaN values.  There is a value of 'O' so we can group all NaN value with those of 'O'.  In addition, the feature values are objects and there are 1,897 unique values.  The unique values will be need to be One-Hot Encoded for modeling purposes.  We  will group all unique values of 100 or less and put them in a categery entitled 'Unknown'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'funder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'] = df_2['funder'].replace(np.nan, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of unique categories in the feature funder are: {len(df_2['funder'].unique())}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.apply(lambda x: x.mask(x.map(x.value_counts())< 100, 'other') if x.name=='funder' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "df_2['funder'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gps_height \n",
    "This feature has a value of 0 which is 34.4% of the feature.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'gps_height') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df_2['gps_height'][df_2['gps_height'] != 0].mean()\n",
    "df_2['gps_height'].replace(0, mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'gps_height') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### installer\n",
    "This feature is defined as the organization that installed the well.  Feature has 3655 NaN values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Government Of Tanzania\t9084\t0.162898\t16.29%\n",
    "NaN\t3635\tNaN\tNaN\n",
    "Danida\t3114\t0.055841\t5.58%\n",
    "Hesawa\t2202\t0.039487\t3.95%\n",
    "Rwssp\t1374\t0.024639\t2.46%\n",
    "...\t...\t...\t...\n",
    "Afric\t1\t0.000018\t0.0%\n",
    "Patrick\t1\t0.000018\t0.0%\n",
    "Manyota Primary School\t1\t0.000018\t0.0%\n",
    "Nipon & Panoco\t1\t0.000018\t0.0%\n",
    "Tanga Cement\t1\t0.000018\t0.0%\n",
    "\n",
    "1898 rows × 3 columns\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "count_value_status(df_2, 'installer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longitude\n",
    "This feature is defined as the GPS coordinate.  #% of this feature has a value of 0.  I used the mean value of the feature to impute the 0 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'longitude') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_mean = df_2[df_2['longitude']>0]['longitude'].mean()\n",
    "df_2.loc[df_2['longitude']==0.00, 'longitude'] = float(longitude_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['longitude'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latitude\n",
    "This feature is defined as the GPS coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_2['latitude'].value_counts(normalize=True)\n",
    "count_value_status(df_2, 'latitude') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_mean = df_2[df_2['latitude']>0]['latitude'].mean()\n",
    "df_2.loc[df_2['latitude']==0, 'latitude'] = float(latitude_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wpt_name and num_private\n",
    "wpt_name is defined as the name of the name of the well.  This feature is an object and has 37,400 unique values.  This would be toom any to One_Hot Encode for modeling purposes and will not be included in the dataset.<br>\n",
    "\n",
    "For num_private, 98.7% of the feature has a value of 0.  This is too many values to impute and will not be included in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['wpt_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'num_private') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basin\n",
    "This is feature is defined as the geographic water basin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'basin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "subvillage : Geographic location\n",
    "region : Geographic location\n",
    "\n",
    "region_code : Geographic location (coded)\n",
    "district_code : Geographic location (coded)\n",
    "\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'region_code') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'district_code') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGA and Ward\n",
    "These features are both defined as the geographic location of the wells.  LGA  has 125 unique value and ward has 2092 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lga                    59400 non-null  object \n",
    " 15  ward  \n",
    "\"\"\"\n",
    "count_value_status(df_2, 'lga') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_value_status(df_2, 'ward')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.apply(lambda x: x.mask(x.map(x.value_counts())< 100, 'Other') if x.name=='lga' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'lga') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population\n",
    "population is defined as the population around the well.  36% of water wells have 0 population around them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'population') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_mean = df_2[df_2['population']>0]['population'].mean()\n",
    "df_2.loc[df_2['population']==0, 'population'] = int(population_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'population') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'public_meeting') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df_2[\"public_meeting\"].mode()[0]\n",
    "df_2[\"public_meeting\"].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['public_meeting'] = list(map(int, df_2['public_meeting']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'public_meeting') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scheme_management\n",
    "scheme_management : Who operates the waterpoint\n",
    "scheme_name : Who operates the waterpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'scheme_management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['scheme_management'] = np.where(df_2['scheme_management'].isnull(),\"Unknown\",df_2['scheme_management'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'scheme_management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "permit is defined as if the well is permitted or not.\n",
    "There are 38852 NaN value.  We can impute NaN to the category with most values.  We need to als also convet the boleean values to \n",
    "numeric.\n",
    "\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=df_2[\"permit\"].mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=df_2[\"permit\"].mode()[0]\n",
    "df_2[\"permit\"].fillna(m,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['permit'] = list(map(int, df_2['permit']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'permit') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construction_year\n",
    "The feature construction_year is defined as the year the waterpoint was constructed.  Unfortnately, 34% of the feature is categorized as 0.  I will replacing the 0 values from the construction year column with the average year year values for the feature. With the cleaned construction year feature I will use feature engineering to create a pump age and an average popultion served per year feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'construction_year') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_test['construction_year'] = X_test['construction_year'].replace({0:1993})\n",
    "\n",
    "mean_yr = df_2[df_2['construction_year']>0]['construction_year'].mean()\n",
    "df_2.loc[df_2['construction_year']==0, 'construction_year'] = int(mean_yr)\n",
    "\"\"\"\n",
    "mean = df_2['construction_year'][df_2['construction_year'] != 0].mean()\n",
    "df_2.construction_year.replace(0, mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'construction_year') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extraction_type_class\n",
    "The features extraction_type, extraction_type_group, extraction_type_class are defined as the kind of extraction the waterpoint uses.  I only included extraction_type_class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'extraction_type_class') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### management\n",
    "Both management and management_group are defined as how the waterpoints are managed.  I only included management in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'management') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.groupby(['management', 'management_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### payment\n",
    "The features payment and payment_type are defined as what the water costs.  I only included payment in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "payment\n",
    "payment-what the water costs\n",
    "payment_type\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'payment') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quality_group\n",
    "Both water_quality and quality_group are defined as the quality of the water.  I only included quality_group in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "water_quality - the quality of water\n",
    "quality_group - the quality of water\n",
    "\"\"\"\n",
    "count_value_status(df_2, 'quality_group') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### quantity_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'quantity_group') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source\n",
    "The features source, source_type and source_class are defined as the source of the water.  The features are duplicates with some variations.  I included only source in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'source') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### waterpoint_type\n",
    "Both features waterpoint_type and waterpoint_type_group have the same defintion and are defined as the kind of waterpoint.  I only included waterpoint_type in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'waterpoint_type') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### age\n",
    "With feature engineering I created a feature to identify the age of the wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features['construction_year'] = features['construction_year'].replace({0:1993})\n",
    "df_2['age'] = df_2['date_recorded'].astype(str).str[:4].astype(int) - df_2['construction_year']\n",
    "df_2['pop_per_year'] = df_2['population'].replace({0:1}) / df_2['age'].replace({0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_value_status(df_2, 'age') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test['age'] = X_test['date_recorded'].astype(str).str[:4].astype(int) - X_test['construction_year']\n",
    "# X_test['pop/year'] = X_test['population'].replace({0:1}) / X_test['age'].replace({0:1})\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_w_hue(df, col= None, hue_col=None, rot=None, figsize=None):\n",
    "    \"\"\"\n",
    "    plots a seaborn countplot for column and hue w/customization\n",
    "    Args\n",
    "    df (dataframe)\n",
    "    col (int or str)\n",
    "    hue_col (int or str)\n",
    "    rot(rotate x label)\n",
    "    figsize (dict)\n",
    "    \"\"\"\n",
    "#     print(df[col].value_counts(dropna=False))\n",
    "#     print('\\n')\n",
    "#     print(round(df[col].value_counts(normalize=True),3))\n",
    "#     dashes = dashes='---'*15\n",
    "#     print(dashes)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    #sns.countplot(data=data, x=col, ax=ax)\n",
    "    sns.countplot(data=df, x=col, hue=hue_col, ax=ax)\n",
    "    label_font = {'weight':'bold','size':15}\n",
    "    ax.set_ylabel('Counts',fontdict=label_font)\n",
    "    ax.set_xlabel(col,fontdict=label_font)\n",
    "    #ax.set_title(f'Distribution of {col.title()}',fontdict=label_font)\n",
    "    ax.set_title(f'How {col.title()} relates to {hue_col.title()}',fontdict=label_font)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontdict={'rotation':rot,'ha':'right'}); \n",
    "    #ax.set_xticklabels(ticklabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distribution(data, col= None, ticklabels=None, figsize=None):\n",
    "    \"\"\"\n",
    "    plots a seaborn countplot for feature w/customization\n",
    "    \n",
    "    Args\n",
    "        df (df)\n",
    "        col (int or str)\n",
    "        figsize (dict)\n",
    "    \"\"\"\n",
    "    print(data[col].value_counts(dropna=False))\n",
    "    print('\\n')\n",
    "    print(round(data[col].value_counts(normalize=True),3))\n",
    "    dashes = dashes='---'*15\n",
    "    print(dashes)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    sns.countplot(data=data, x=col, ax=ax)\n",
    "    label_font = {'weight':'bold','size':15}\n",
    "    ax.set_ylabel('Counts',fontdict=label_font)\n",
    "    ax.set_xlabel(col,fontdict=label_font)\n",
    "    ax.set_title(f'Distribution of {col.title()}',fontdict=label_font)\n",
    "    ax.set_xticklabels(ticklabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target\n",
    "The target is imbalanced because category 0 which is 54% of the feature, category 1 is 38% and category 2 is 0.07% of the feature.  The imblance could impact the model's performance so it will be addressed further below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_distribution(df_1, col='target',ticklabels=['functional / 0','non-functional / 1','functional needs repair / 2'],figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### district_code\n",
    "The below plot shows that districts 1,2,3 4 have the highest number of performing wells.  However, there is also a large number of non-functioning wells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='district_code', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### funder\n",
    "We were looking to see if the top funders give us some indcation of the functionlaity of the wells.  Other is the largest category which isn't helpful because it's not specific. Government Of Tanzania is the next largest group and they have funded 9084 wells.  A little over 4,000 wells are functioning but around 5,000 wells aren't functioning.  The Government of Tanzania isn't very good at funding wells projects that are functional.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['funder'].value_counts(dropna=False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funder_10 = df_3[(df_3['funder'] == 'other') | (df_3[\"funder\"] == 'Government Of Tanzania')\n",
    "                 |(df_3[\"funder\"] == '0')| (df_3[\"funder\"] == 'Danida')\n",
    "                 |(df_3[\"funder\"] == 'Hesawa') |(df_3[\"funder\"] == 'Rwssp') \n",
    "                 |(df_3[\"funder\"] == 'World Bank') |(df_3[\"funder\"] == 'Kkkt')\n",
    "                 | (df_3[\"funder\"] == 'World Vision')| (df_3[\"funder\"] == 'Unicef')\n",
    "                  | (df_3[\"funder\"] == 'Tasaf')]\n",
    "funder_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(funder_10, col='funder', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does location impact functionality of a well\n",
    "The below plot is really helpful because it shows where the wells are located and their functionality.  In the southeast section there is a cluster of non-functioning wells.  Further research is warranted.  Is there any correlation with district, population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x='longitude', y='latitude', hue='target', data=df_2)#, ax=ax\n",
    "plt.title('Water Well Location and Functionality')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does region_code impact functionality?\n",
    "It's crucial to see which districts have the highest number of wells and their status.  The plot gives us a quick summary of the number of wells in each district and their status.  Region 11 has highest number of wells with 5300; around 4,200 are functioning, around 1,000 are non-functioning and around 100 are in need of repairs.  Region 17 has the second largest with 5,100 wells; around 3,000 are functioning wells and 1,500 are non-functioning.  In constrast it  shows that regions 8,9,40, 60, 80, 90 and 99 have very few wells and most are non-functioning.\n",
    "\n",
    "Also, by grouping the features we can see how region and water quality are realted to functionality.  For example, region 8 has among the lowest number of wells and most are non-fucntioning.  We can see that most of the water quality is 'salty' which isn't good.  Whereas, region 11 has the most number of wells and 4120 of the wells have 'good' water quality which as explained below contributes to a functioning well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='region_code', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "df_2.groupby(['target', 'region_code','quality_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the quality of the water impact functionality\n",
    "The plot show that there are 6 categories for water quality.  The majority of the wells are in the category of good which constitutes 50,818 of the wells.  Of this category around 29,000 are functioning and around 18,000 are non-functioning.  If the well has 'good water' quality there is a higher chance that it is functioning but there is still a high probability it's not functioning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='quality_group', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does quantity of water impact well functionality?\n",
    "The below shows there are 5 categories in this feature.  There are 33186\twells in the 'enough' category.  The below plot shows that wells with enough water constitute the largest number of wells and the highest functionality.  There are around 24,000 functioning wells with enough water and around 8,500 are non-functioning.  Based on the below it looks like if the well has a enough water it contributes to the functionality of the well.  The wells need to be tested to make sure they have enough water. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(df_2, col='quantity_group', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the age of the well impact its functionality?\n",
    "Below is a plot of top 20 largest well age value counts.  The largest group of wells are 14.1 years.  There are 13,343 wells in this age group.  The below plot shows that of this group around 6,700 wells are functioning, 5,500 are not functioning and around 1,200 in need of repair.  The next largest group is 15.1 years.  There are 5,142 wells in this group; around 3,000 are functioning and around 2,100 are functioning.<br>\n",
    "Does the below plot give us any insights about the relationship between age and the target.  First, aside from years 14 and 15.1 years, we can see that there are more wells that are 1 to 14 yrs old.  Also, more of the wells in these age groups are functioning.  It makes sense because Tanzania was responding to the water crisis so more wells were built in the later\n",
    "years but there still are a high number of non-functioning wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample = df_2.groupby(\"age\").filter(lambda x: len(x) > 800)\n",
    "my_sample['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sample['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_w_hue(my_sample, col='age', hue_col='target',rot=40,figsize=(14,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of Data\n",
    "The pre-processing of the data will involve One-Hot Encoding the features with object data types because\n",
    "non-numeric values can't be inputted into the models.  In addition, this is a ternary classification problem because the target has three classifiction values: functional, non functional and functional needs repair. As displayed above we can see that value_counts are not balanced.  This could impact the accuracy of the model's performance.  I  ran the SMOTE method the training set to resample the set and get equal values for each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_obj = ['installer','basin','lga','scheme_management','extraction_type_class','management','payment','quality_group',\n",
    "            'quantity_group','source','waterpoint_type']\n",
    "cols_num = ['gps_height','latitude','longitude','district_code','region_code','permit','construction_year','population','age','pop_per_year']\n",
    "\n",
    "df_3 = df_2[cols_obj]\n",
    "df_4 = df_2[cols_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df = pd.get_dummies(df_3, cols_obj, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df_4, one_hot_df], axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result.copy()\n",
    "y = df_2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_resampled.shape)\n",
    "print(y_train_resampled.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_dict = {\n",
    "    'KNN': { 'model' : KNeighborsClassifier(),\n",
    "                         'params' : { \n",
    "                                        \"n_neighbors\" : [3,5,7,9,11,15,19,21],\n",
    "                                        \"weights\" : ['uniform', 'distance']}\n",
    "             },\n",
    "    'logisticR': { 'model' : LogisticRegression(),\n",
    "                         'params' : { \n",
    "                             'fit_intercept':[False], \n",
    "                             'C':[1e12], \n",
    "                             'solver':['liblinear']}\n",
    "             }              \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for model_name, mp in model_dict.items():\n",
    "#      clf = GridSearchCV(mp['model'], mp['params'],cv=5,  return_train_score=False) #refit='f1_weighted',\n",
    "#      clf.fit(X_train, y_train)\n",
    "#      y_pred = clf.predict(X_test) \n",
    "    \n",
    "#      accuracy = accuracy_score(y_test, y_pred)\n",
    "#      scores.append({\n",
    "#       'model':model_name,\n",
    "#       'accuracy': accuracy,\n",
    "#       'best params': clf.best_params_\n",
    "#       })\n",
    "# pd.set_option('display.max_colwidth', None)    \n",
    "# gscv_models = pd.DataFrame(scores) #, columns=['model', 'accuracy', 'f1', 'roc','best score','best params']\n",
    "# gscv_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification_model(X_train_resampled, X_test, y_train_resampled, y_pred,\n",
    "                              normalize='true',cmap='Blues',figsize=[10,5]):\n",
    "      \n",
    "    # Classification Report / Accuracy Score \n",
    "    print(dashes)\n",
    "    print(\"Classification Report\")\n",
    "    print(dashes)\n",
    "    classes = ['0/Functional','1/Non-functioning','2/Needs Repair']\n",
    "    print(metrics.classification_report(y_test,y_pred,target_names=classes))  \n",
    "    print(dashes)\n",
    "    print('\\n')\n",
    "   \n",
    "    plt.figure(figsize=(8,8))\n",
    "    rf_cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap='Blues')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "model = knn.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred =model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=123, n_estimators=400,class_weight='balanced',\n",
    "                           max_depth = 80,max_features = 'auto', criterion ='gini')\n",
    "model_rf = rf.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred =model_rf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,12))\n",
    "plt.title('Feature Importances')\n",
    "feat_importances = pd.Series(model_rf.feature_importances_, index=result.columns)\n",
    "ax = feat_importances.nlargest(20).plot(kind='barh')\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model_dict =  { \n",
    "                   'max_depth': [2,3,4], \n",
    "                    'n_estimators': [100,200,250],\n",
    "                    'learning_rate' :[0.01,0.03,0.05,0.1]\n",
    "                                             }                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(use_label_encoder=False, verbosity = 0, probability=True)\n",
    "model_xgb = xgb.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_xgb=model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = decomposition.PCA()\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# lr = LogisticRegression('fit_intercept':[False], \n",
    "#                              'C':[1e12], \n",
    "#                              'solver':['liblinear'])\n",
    "# rf = RandomForestClassifier(class_weight='balanced', \n",
    "#                             n_jobs=-1, \n",
    "#                             n_estimators=350)\n",
    "\n",
    "# steps = [\n",
    "#         ('lr', lr),\n",
    "#         ('random_forest', rf)]\n",
    "\n",
    "# pipeline = Pipeline(steps)\n",
    "# parameters = dict(\n",
    "#                 #pca__n_components=[40, 100, 300], \n",
    "#                 random_forest__max_features=['auto', 'log2']\n",
    "#                 )\n",
    "\n",
    "# gs = GridSearchCV(pipeline, param_grid=parameters)\n",
    "# gs.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# lr = LogisticRegression('fit_intercept':[False], \n",
    "#                              'C':[1e12], \n",
    "#                              'solver':['liblinear'])\n",
    "# rf = RandomForestClassifier(class_weight='balanced', \n",
    "#                             n_jobs=-1, \n",
    "#                             n_estimators=350)\n",
    "\n",
    "# steps = [\n",
    "#         ('lr', lr),\n",
    "#         ('random_forest', rf)]\n",
    "\n",
    "# pipeline = Pipeline(steps)\n",
    "# parameters = dict(\n",
    "#                 #pca__n_components=[40, 100, 300], \n",
    "#                 random_forest__max_features=['auto', 'log2']\n",
    "#                 )\n",
    "\n",
    "# gs = GridSearchCV(pipeline, param_grid=parameters)\n",
    "# gs.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gs.best_score_)\n",
    "# print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = gs.best_estimator_\n",
    "# rf.fit(X_train_resampled, y_train_resampled)\n",
    "# #feature_importances = rf.best_estimator_._final_estimator.feature_importances_\n",
    "# y_pred = rf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0/Functional','1/Non-functioning','2/Needs Repair']\n",
    "print(metrics.classification_report(y_test,y_pred,target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "rf_cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "#indices = np.argsort(importances)\n",
    "\n",
    "# features = df_data.columns\n",
    "# plt.figure(figsize=(12,10))\n",
    "# plt.title('Feature Importances')\n",
    "# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "# plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "# plt.xlabel('Relative Importance')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR_params = gscv_models.iloc[1]['best params']\n",
    "logisticR = LogisticRegression(**logisticR_params)\n",
    "model_lr = logisticR.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_lr =model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['0/Functional','1/Non-functioning','2/Needs Repair']\n",
    "print(metrics.classification_report(y_test,y_pred_lr,target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "rf_cm = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(rf_cm, annot=True, fmt=\"d\", cmap='Blues')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eval_classification_model(X_train_resampled, X_test, \n",
    "                 y_train_resampled, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_params = gscv_models.iloc[2]['best params']\n",
    "# rf = RandomForestClassifier(**rf_params)\n",
    "# model_rf = rf.fit(X_train_resampled, y_train_resampled)\n",
    "# y_pred_rf=model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_rf = eval_classification_model(X_train_resampled, X_test, \n",
    "#                  y_train_resampled, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = result.copy()    #df_2.drop('target',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "# features = df_data.columns\n",
    "# plt.figure(figsize=(12,10))\n",
    "# plt.title('Feature Importances')\n",
    "# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "# plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "# plt.xlabel('Relative Importance')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO don't use\n",
    "# param_grid = {'learning_rate': [0.075, 0.07],\n",
    "#                       'max_depth': [6, 7],\n",
    "#                       'min_samples_leaf': [7,8],\n",
    "#                       'max_features': [1.0],\n",
    "#                       'n_estimators':[100, 200]} \n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1,\n",
    "#                             criterion= 'entropy',max_features= 'sqrt',\n",
    "#                              min_samples_split= 10,class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put is null values in unknown category\n",
    "# df_2['installer'] = np.where(df_2['installer'].isnull(),\"Unknown\",df_2['installer'])\n",
    "\n",
    "# df_2['installer'] = np.where(df_2['installer'].isnull(),\"Unknown\",df_2['installer'])\n",
    "\n",
    "# amount_tsh_mean = df_2[df_2['amount_tsh']>0]['amount_tsh'].mean()\n",
    "# df_2.loc[df_2['amount_tsh']==0, 'amount_tsh'] = int(amount_tsh_mean)\n",
    "\n",
    "# #Matt Kirby\n",
    "# features['construction_year'] = features['construction_year'].replace({0:1993})\n",
    "# features['age'] = features['date_recorded'].astype(str).str[:4].astype(int) - features['construction_year']\n",
    "# features['pop/year'] = features['population'].replace({0:1}) / features['age'].replace({0:1})\n",
    "\n",
    "# features['water_/_person'] = features['amount_tsh'].replace({0:1}) / features['population'].replace({0:1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
